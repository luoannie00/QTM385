{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00278108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install package_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff335f76",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e03f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import KNNImputer\n",
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "from pygam import LinearGAM, s, te\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b4ed1",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dat = pd.read_csv('single_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef888a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create duplicate dataset\n",
    "dat = original_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e5956",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc185c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dat, x='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac226732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "percentile25 = dat['Price'].quantile(0.25)\n",
    "percentile75 = dat['Price'].quantile(0.75)\n",
    "IQR = percentile75 - percentile25\n",
    "dat = dat.loc[(dat['Price']>percentile25-1.5*IQR) & (dat['Price']<percentile75+1.5*IQR),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows removed\n",
    "len(original_dat) - len(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298caec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non-numeric columns\n",
    "dat = dat.drop(['Street','City','State','Zip','geoadd','CheckAddDuplicate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60675aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=dat, x='Price', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945585bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset explainations\n",
    "#original_dat (uncleaned dataset)\n",
    "#dat (cleaned dataset with NA values)\n",
    "#the response variable does not have NAs\n",
    "y = dat['Price'].values\n",
    "X = dat.iloc[: , 1:]\n",
    "#X_simple (filled NAs with column means)\n",
    "#X_knn (filled NAs with KNNImputer)\n",
    "#X_forest (folled NAs with MissForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cbe05",
   "metadata": {},
   "source": [
    "## simple approach (fill NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a04964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple = X.fillna(X.mean()).values\n",
    "gam_reg = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5)).fit(X_simple, y)\n",
    "cv_score = sqrt(gam_reg.statistics_['GCV'])\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05afa69b",
   "metadata": {},
   "source": [
    "## KNNImputer (fill NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a different approach to NA\n",
    "k = list(range(5,100,5)) + list(range(100,501,50))\n",
    "outsample = []\n",
    "\n",
    "for i in range(len(k)):\n",
    "    #create duplicate predictor dataset with missing values\n",
    "    X_temp = X\n",
    "    #build the model\n",
    "    imputer = KNNImputer(n_neighbors=k[i])\n",
    "    X_temp = pd.DataFrame(imputer.fit_transform(X_temp)).values\n",
    "    #evaluate on gam model\n",
    "    gam_reg = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5)).fit(X_temp, y)\n",
    "    cv_score = sqrt(gam_reg.statistics_['GCV'])\n",
    "    outsample.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_table = pd.DataFrame({'k':k, 'out-of-sample error':outsample})\n",
    "sns.lineplot(data=knn_table, x='k', y='out-of-sample error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select optimal k to finalize the model\n",
    "imputer = KNNImputer(n_neighbors=100)\n",
    "X_knn = pd.DataFrame(imputer.fit_transform(X), columns=list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44b9df",
   "metadata": {},
   "source": [
    "## MissForest (fill NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MissForest()\n",
    "X_forest = pd.DataFrame(imputer.fit_transform(X), columns=list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gam_reg = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5)).fit(X_forest, y)\n",
    "cv_score = sqrt(gam_reg.statistics_['GCV'])\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b5c3e",
   "metadata": {},
   "source": [
    "## KNN (not scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93113d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep the data\n",
    "X = X_forest[['SqFt','Acreage','Beds','Baths']].values\n",
    "# X = X_knn[['Latitude','Longitude']].values\n",
    "# X = X_knn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92647517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model\n",
    "outsample = []\n",
    "k = list(range(1,20)) + list(range(20,100,5)) + list(range(100,501,100))\n",
    "\n",
    "for i in range(len(k)):\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k[i])\n",
    "    cv_score = cross_validate(knn_model, X, y, cv=10, scoring='neg_mean_squared_error')['test_score']\n",
    "    outsample.append(np.mean(np.sqrt(-cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32438a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_table = pd.DataFrame({'k':k, 'out-of-sample error':outsample})\n",
    "sns.lineplot(data=knn_table, x='k', y='out-of-sample error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalk = k[outsample.index(min(outsample))]\n",
    "print('The best k for out-of-sample prediction: ' + str(optimalk))\n",
    "print('The best cv out-of-sample error: ' + str(round(min(outsample),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b7208",
   "metadata": {},
   "source": [
    "## KNN (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_forest)\n",
    "X = scaler.transform(X_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X, columns=list(X_forest.columns)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model\n",
    "outsample = []\n",
    "k = list(range(1,50)) + list(range(50,501,50))\n",
    "\n",
    "for i in range(len(k)):\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k[i])\n",
    "    cv_score = cross_validate(knn_model, X, y, cv=10, scoring='neg_mean_squared_error')['test_score']\n",
    "    outsample.append(np.mean(np.sqrt(-cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56506ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_table = pd.DataFrame({'k':k, 'out-of-sample error':outsample})\n",
    "sns.lineplot(data=knn_table, x='k', y='out-of-sample error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalk = k[outsample.index(min(outsample))]\n",
    "print('The best k for out-of-sample prediction: ' + str(optimalk))\n",
    "print('The best cv out-of-sample error: ' + str(round(min(outsample),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0a865",
   "metadata": {},
   "source": [
    "## split the dataset (too much computation cost to do CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "X = X_forest.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daf0a7",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df86fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model\n",
    "maxfeatures = [2,3,4,5,6]\n",
    "samplesleaf = list(range(1,15)) + list(range(15,50,5))\n",
    "bestmaxfeature = 99999\n",
    "bestsamplesleaf = 99999\n",
    "best_outsample = 99999\n",
    "\n",
    "for i in tqdm(range(len(maxfeatures))):\n",
    "    for j in range(len(samplesleaf)):\n",
    "        rf_model = RandomForestRegressor(n_estimators=500, \n",
    "                                         max_features=maxfeatures[i], \n",
    "                                         min_samples_leaf=samplesleaf[j])\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        #out-of-sample\n",
    "        test_preds = rf_model.predict(X_test)\n",
    "        rmse = sqrt(mean_squared_error(y_test, test_preds))\n",
    "        if rmse < best_outsample:\n",
    "            bestmaxfeature = maxfeatures[i]\n",
    "            bestsamplesleaf = samplesleaf[j]\n",
    "            best_outsample = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best max_features for out-of-sample prediction: ' + str(bestmaxfeature))\n",
    "print('The best min_samples_leaf for out-of-sample prediction: ' + str(bestsamplesleaf))\n",
    "print('The best out-of-sample error: ' + str(round(best_outsample,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf089d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time: 5 min.\n",
    "#best max_features: 6\n",
    "#best min_samples_leaf: 3\n",
    "#best out-of-sample error: 267.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56dbc3",
   "metadata": {},
   "source": [
    "## interaction b/t longitude & latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist = list(np.linspace(min(X_forest['Latitude']), max(X_forest['Latitude']), 50))\n",
    "ylist = list(np.linspace(min(X_forest['Longitude']), max(X_forest['Longitude']), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5735c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table = pd.DataFrame({'Latitude':xlist*50, 'Longitude':np.repeat(ylist,50)})\n",
    "temp_table['SqFt'] = np.mean(X_forest['SqFt'])\n",
    "temp_table['Acreage'] = np.mean(X_forest['Acreage'])\n",
    "temp_table['Beds'] = np.mean(X_forest['Beds'])\n",
    "temp_table['Baths'] = np.mean(X_forest['Baths'])\n",
    "temp_table = temp_table.reindex(columns = list(X_forest.columns))\n",
    "ada_model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10), \n",
    "                              n_estimators=500, \n",
    "                              learning_rate=0.05)\n",
    "ada_model.fit(X_train, y_train)\n",
    "temp_table['Price'] = ada_model.predict(temp_table)\n",
    "temp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data =\n",
    "    go.Contour(\n",
    "        z=temp_table['Price'],\n",
    "        x=temp_table['Latitude'], # horizontal axis\n",
    "        y=temp_table['Longitude'] # vertical axis\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02557be1",
   "metadata": {},
   "source": [
    "## adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c370d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model\n",
    "base_model = list(range(1,16))\n",
    "tree_num = [500,1000]\n",
    "learning_rate = [0.001,0.005,0.01,0.05,0.1,0.5]\n",
    "best_outsample = 99999\n",
    "best_base_model = 99999\n",
    "best_tree_num = 99999\n",
    "best_learning_rate = 99999\n",
    "\n",
    "for i in tqdm(range(len(base_model))):\n",
    "    for j in range(len(tree_num)):\n",
    "        for k in range(len(learning_rate)):\n",
    "            ada_model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=base_model[i]), \n",
    "                                          n_estimators=tree_num[j], \n",
    "                                          learning_rate=learning_rate[k])\n",
    "            ada_model.fit(X_train, y_train)\n",
    "            #out-of-sample\n",
    "            test_preds = ada_model.predict(X_test)\n",
    "            rmse = sqrt(mean_squared_error(y_test, test_preds))\n",
    "            if rmse < best_outsample:\n",
    "                best_outsample = rmse\n",
    "                best_base_model = base_model[i]\n",
    "                best_tree_num = tree_num[j]\n",
    "                best_learning_rate = learning_rate[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ce4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best base_model_depth for out-of-sample prediction: ' + str(best_base_model))\n",
    "print('The best tree_num for out-of-sample prediction: ' + str(best_tree_num))\n",
    "print('The best learning_rate for out-of-sample prediction: ' + str(best_learning_rate))\n",
    "print('The best out-of-sample error: ' + str(round(best_outsample,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time: 24 min.\n",
    "#best base_model_depth: 10\n",
    "#best tree_num: 500\n",
    "#best learning_rate: 0.05\n",
    "#best out-of-sample error: 266.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffaa9c9",
   "metadata": {},
   "source": [
    "## gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb67879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model\n",
    "maxdepth = [1,2,3,4,5,6,7,8,9,10]\n",
    "tree_num = [500,1000,1500]\n",
    "learning_rate = [0.001,0.005,0.01,0.05,0.1,0.5]\n",
    "best_outsample = 99999\n",
    "best_maxdepth = 99999\n",
    "best_tree_num = 99999\n",
    "best_learning_rate = 99999\n",
    "\n",
    "for i in tqdm(range(len(maxdepth))):\n",
    "    for j in range(len(tree_num)):\n",
    "        for k in range(len(learning_rate)):\n",
    "            grad_model = GradientBoostingRegressor(max_depth=maxdepth[i], \n",
    "                                                   n_estimators=tree_num[j], \n",
    "                                                   learning_rate=learning_rate[k])\n",
    "            grad_model.fit(X_train, y_train)\n",
    "            #out-of-sample\n",
    "            test_preds = grad_model.predict(X_test)\n",
    "            rmse = sqrt(mean_squared_error(y_test, test_preds))\n",
    "            if rmse < best_outsample:\n",
    "                best_outsample = rmse\n",
    "                best_maxdepth = maxdepth[i]\n",
    "                best_tree_num = tree_num[j]\n",
    "                best_learning_rate = learning_rate[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb63d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best max_depth for out-of-sample prediction: ' + str(best_maxdepth))\n",
    "print('The best tree_num for out-of-sample prediction: ' + str(best_tree_num))\n",
    "print('The best learning_rate for out-of-sample prediction: ' + str(best_learning_rate))\n",
    "print('The best out-of-sample error: ' + str(round(best_outsample,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e817673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time: 21 min.\n",
    "#best max_depth: 6\n",
    "#best tree_num: 1500\n",
    "#best learning_rate: 0.005\n",
    "#best out-of-sample error: 265.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efdf45",
   "metadata": {},
   "source": [
    "## MLP neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7093b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_scaled, columns=list(X_forest.columns)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa199b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test_scaled, columns=list(X_forest.columns)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0796c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "#tune the model\n",
    "hiddenlayer = [(10,),(20,),(30,),(40,),(50,),(60,),(70,),(80,),(90,),(100,),\n",
    "               (10,10,),(20,20,),(30,30,),(40,40,),(50,50,),]\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "best_outsample = 99999\n",
    "best_hiddenlayer = 99999\n",
    "best_activation = 99999\n",
    "\n",
    "for i in tqdm(range(len(hiddenlayer))):\n",
    "    for j in range(len(activation)):\n",
    "        nn_model = MLPRegressor(hidden_layer_sizes=hiddenlayer[i], \n",
    "                                activation=activation[j], \n",
    "                                learning_rate_init=0.005, \n",
    "                                max_iter=10000, \n",
    "                                random_state=12345)\n",
    "        nn_model.fit(X_train_scaled, y_train)\n",
    "        #out-of-sample\n",
    "        test_preds = nn_model.predict(X_test_scaled)\n",
    "        rmse = sqrt(mean_squared_error(y_test, test_preds))\n",
    "        if rmse < best_outsample:\n",
    "            best_outsample = rmse\n",
    "            best_activation = activation[j]\n",
    "            best_hiddenlayer = hiddenlayer[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best hiddenlayer for out-of-sample prediction: ' + str(best_hiddenlayer))\n",
    "print('The best activation for out-of-sample prediction: ' + str(best_activation))\n",
    "print('The best out-of-sample error: ' + str(round(best_outsample,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6dd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time: 32 min.\n",
    "#best hiddenlayer: (90,)\n",
    "#best activation: 'tanh'\n",
    "#best out-of-sample error: 271.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9467f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3401c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thoughts\n",
    "#1. KNNImputer and MissForest to fill NAs (already done)\n",
    "#2. KNN and rf to predict prices (already done)\n",
    "#3. learn boosting tree (adaboost and gradientboost) and neural network (MLP) to predict prices (already done)\n",
    "#4. visualize prediction prices on (longitude, latitude) holding the other variables constant (already done)\n",
    "\n",
    "#aside\n",
    "#the dataset is raw, we need to remove the outliers (already done)\n",
    "#need to add CV measures on some models (already done)\n",
    "#the ultimate goal is to try to make better predictions on price than we did in summer\n",
    "\n",
    "#final deliverable (a short paper)\n",
    "#introduction\n",
    "#table of model performance\n",
    "#table of model computation time\n",
    "#plot of best models performance\n",
    "#explaination of best models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
