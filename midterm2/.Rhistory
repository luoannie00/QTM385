library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
# data read-in
train_x <- read.csv('MNISTTrainXV2.csv')
train_y <- read.csv('MNISTTrainY.csv')
test_x <- read.csv('MNISTTestXRand.csv')
test_y <- read.csv("MNISTTestYRand.csv")
validation_x <- read.csv('MNISTValidationX.csv')
validation_y <- read.csv('MNISTValidationY.csv')
View(train_x)
View(train_y)
# plot function
plot_digit <- function(x, bw = FALSE,...){
if(sqrt(length(x)) != round(sqrt(length(x)))){
stop(print("Not a square image! Something is wrong here."))
}
n <- sqrt(length(x))
if(bw == TRUE){
x <- as.numeric(x > 50)*256
}
par(pty = "s")
image(matrix(as.matrix(x), nrow = n)[,n:1], col = gray(12:1 / 12), ...)
}
#Example
plot_digit(x = train_x[1,], bw = FALSE, main = "True Class = 0")
#Example
plot_digit(x = train_x[1,], bw = TRUE, main = "True Class = 0")
#Example
plot_digit(x = train_x[1,], bw = FALSE, main = "True Class = 0")
train_y[50,]
train_y[200,]
train_y[1500,]
train_y[2800,]
train_y[50,] #0
train_y[1500,] #0
train_y[2800,] #1
train_y[6500,] #1
train_y[10000,]
train_y[13780,]
train_y[17000,]
train_y[20000,]
train_y[23730,]
train_y[50,] #0
plot_digit(x = train_x[50,], bw = FALSE, main = "True Class = 0")
train_y[1500,] #0
plot_digit(x = train_x[1500,], bw = FALSE, main = "True Class = 0")
train_y[2800,] #1
plot_digit(x = train_x[2800,], bw = FALSE, main = "True Class = 1")
train_y[6500,] #2
plot_digit(x = train_x[6500,], bw = FALSE, main = "True Class = 2")
train_y[10000,] #3
plot_digit(x = train_x[10000,], bw = FALSE, main = "True Class = 3")
train_y[13780,] #5
plot_digit(x = train_x[13780,], bw = FALSE, main = "True Class = 5")
train_y[17000,] #6
plot_digit(x = train_x[17000,], bw = FALSE, main = "True Class = 6")
train_y[20000,] #7
plot_digit(x = train_x[20000,], bw = FALSE, main = "True Class = 7")
train_y[23730,] #9
plot_digit(x = train_x[23730,], bw = FALSE, main = "True Class = 9")
x_split <- exp(seq(-10,10,length = 50))
x_split <- seq(0,25000,length = 2500)
x_split <- seq(0,25000,length = 10)
x_split <- seq(1,25000,length = 10)
x_split <- seq(1,25000,10)
x_split <- seq(1,2500, 25000)
x_split <- seq(1,2500,25000)
x_split <- seq(1,25000,2500)
x_split <- seq(1,25000,2499)
x_split <- seq(0,25000,2500)
x_split <- seq(1,25000,2500)
#0 digit
zero_train <- mean(test_x[1:2500])
#0 digit
zero_train <- mean(test_x[1:2500,])
rm(x_split)
#0 digit
zero_train <- c()
for (i in 1:144){
zero_train[i] <- mean(test_x[1:2500,i])
}
mean_train <- (, nrow = 10, ncol = 1)
mean_train <- (nrow = 10, ncol = 1)
mean_train <- matrix(, nrow = 10, ncol = 1)
View(mean_train)
mean_train <- matrix(, nrow = 10, ncol = 144)
for (i in 1:144){
mean_train[1,i] <- mean(test_x[1:2500,i])
}
x_split <- seq(1,25000,2500)
x_splot
x_split
x_split <- seq(1,27500,2500)
x_split
mean_train <- matrix(, nrow = 10, ncol = 144)
x_split <- seq(1,27500,2500)
for (i in 1:144){
for (j in 1:10)
mean_train[j,i] <- mean(test_x[x_split[j]:(x_split[j+1]-1),i])
}
mean_train <- matrix(nrow = 10, ncol = 144)
x_split <- seq(1,27500,2500)
for (i in 1:144){
for (j in 1:10)
mean_train[j,i] <- mean(test_x[x_split[j]:(x_split[j+1]-1),i])
}
x_split
mean(test_x[x_split[4]:(x_split[4+1]-1),1])
mean(test_x[x_split[5]:(x_split[6+1]-1),1])
View(test_x)
mean(test_x[10001:12500,1])
mean(test_x[7501:10000,1])
library(ggplot2)
library(data.table)
library(tidyverse)
library(glmnet)
library(MASS)
library(splitTools)
library(naivebayes)
library(nnet)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
# data read-in
cancer_train <- read.csv('cancerTrain.csv')
cancer_test <- read.csv('cancerTest.csv')
wine_train <- read.csv('wineTrain.csv')
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
# data read-in
train_x <- read.csv('MNISTTrainXV2.csv')
train_y <- read.csv('MNISTTrainY.csv')
test_x <- read.csv('MNISTTestXRand.csv')
test_y <- read.csv("MNISTTestYRand.csv")
validation_x <- read.csv('MNISTValidationX.csv')
validation_y <- read.csv('MNISTValidationY.csv')
# plot function
plot_digit <- function(x, bw = FALSE,...){
if(sqrt(length(x)) != round(sqrt(length(x)))){
stop(print("Not a square image! Something is wrong here."))
}
n <- sqrt(length(x))
if(bw == TRUE){
x <- as.numeric(x > 50)*256
}
par(pty = "s")
image(matrix(as.matrix(x), nrow = n)[,n:1], col = gray(12:1 / 12), ...)
}
#Example
plot_digit(x = train_x[1,], bw = FALSE, main = "True Class = 0") #x vector length = square of integer
plot_digit(x = train_x[1,], bw = TRUE, main = "True Class = 0")
train_y[50,] #0
plot_digit(x = train_x[50,], bw = FALSE, main = "True Class = 0")
train_y[1500,] #0
plot_digit(x = train_x[1500,], bw = FALSE, main = "True Class = 0")
train_y[2800,] #1
plot_digit(x = train_x[2800,], bw = FALSE, main = "True Class = 1")
train_y[6500,] #2
plot_digit(x = train_x[6500,], bw = FALSE, main = "True Class = 2")
train_y[10000,] #3
plot_digit(x = train_x[10000,], bw = FALSE, main = "True Class = 3")
train_y[13780,] #5
plot_digit(x = train_x[13780,], bw = FALSE, main = "True Class = 5")
train_y[17000,] #6
plot_digit(x = train_x[17000,], bw = FALSE, main = "True Class = 6")
train_y[20000,] #7
plot_digit(x = train_x[20000,], bw = FALSE, main = "True Class = 7")
train_y[23730,] #9
plot_digit(x = train_x[23730,], bw = FALSE, main = "True Class = 9")
mean_train <- matrix(nrow = 10, ncol = 144)
x_split <- seq(1,27500,2500)
for (i in 1:144){
for (j in 1:10)
mean_train[j,i] <- mean(train_x[x_split[j]:(x_split[j+1]-1),i])
}
View(mean_train)
for (j in 1:10){
plot_digit(x = mean_train[j,], bw = FALSE)
}
