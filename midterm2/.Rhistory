for (i in 1:length(depth)){
for (j in 1:length(learn_rate)){
for (k in 1:length(treeNum)){
xgbMod <- xgboost(data = as.matrix(xgb_train), label = xgb_trainY, max.depth = depth[i],
eta = learn_rate[j], nrounds = treeNum[k],
objective = "binary:logistic", verbose = 0)
#we use validation data to calculate temp_err to prevent overfit
temp_err <- mean(round(predict(xgbMod, newdata = as.matrix(xgb_valid))) != xgb_validY)
if (temp_err < optimal_err){
optimal_err<-temp_err
optimal_treeNum<-k
optimal_learn_rate<-j
optimal_depth<-i
}
}
}
}
depth[optimal_depth]
learn_rate[optimal_learn_rate]
treeNum[optimal_treeNum]
#finalized model
FN_xgb_classifier <- xgboost(data = as.matrix(xgb_train), label = xgb_trainY,
max.depth = depth[optimal_depth], eta = learn_rate[optimal_learn_rate],
nrounds = treeNum[optimal_treeNum],
objective = "binary:logistic", verbose = 0)
FN_xgb_oos <- mean(round(predict(xgbMod, newdata = as.matrix(xgb_valid))) != xgb_validY)
FN_xgb_oos
fourNine_result$xgb <- FN_xgb_oos
fourNine_result
temp_err
rf_MTRY <- varNum[optimal_varNum]
#Model Stacking (more than 2 classes would need H2)
#See all available methods with listWrappers()
#Split data into x_train and y_train
stack_trainY <- p3_trainY
stack_train <- p3_train
stack_train$p3_trainY <- NULL
stack_trainY <- p3p1_validY #recode to 0,1
stack_valid <- p3_valid
stack_valid$p3_validY <- NULL
#Let's run a model stack with 5 models: random forest, svm, logistic regression,
#qda, and mean (we just take the average)
#Set some tuning parameters
SL.ksvm.better <- function(...){
SL.ksvm(..., C = cost)
}
SL.ranger.better <- function(...){
SL.ranger(..., num.trees = 1000, mtry = rf_MTRY)
}
#Get 5 fold CV estimate of Risk from superlearner
stack <- SuperLearner(Y = stack_trainY, X = stack_train, family = binomial(), cvControl = list(V = 10),
SL.library = c("SL.ranger.better", "SL.ksvm.better","SL.glm","SL.qda","SL.mean"))
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
library(mgcv)
library(gbm)
library(xgboost)
library(SuperLearner)
install.packages('SuperLearner')
library(SuperLearner)
#Get 5 fold CV estimate of Risk from superlearner
stack <- SuperLearner(Y = stack_trainY, X = stack_train, family = binomial(), cvControl = list(V = 10),
SL.library = c("SL.ranger.better", "SL.ksvm.better","SL.glm","SL.qda","SL.mean"))
stack_trainX <- p3_trainX
#Get 5 fold CV estimate of Risk from superlearner
stack <- SuperLearner(Y = stack_trainY, X = stack_trainX, family = binomial(), cvControl = list(V = 10),
SL.library = c("SL.ranger.better", "SL.ksvm.better","SL.glm","SL.qda","SL.mean"))
fourNine_result
stack_trainY <- p3_trainYfactored
stack_train <- p3_trainFactored
stack_train$p3_trainY <- NULL
#Let's run a model stack with 5 models: random forest, svm, logistic regression,
#qda, and mean (we just take the average)
#Set some tuning parameters
SL.ksvm.better <- function(...){
SL.ksvm(... = , type = "C-svc",
kernel = "rbfdot", C = cost, cross = 5, prob.model = TRUE)
}
SL.ranger.better <- function(...){
SL.ranger(... = ,
num.trees = 1000, importance = "permutation",
mtry = rf_MTRY, classification = TRUE)
}
#Get 5 fold CV estimate of Risk from superlearner
stack <- SuperLearner(Y = stack_trainY, X = stack_train, family = binomial(), cvControl = list(V = 10),
SL.library = c("SL.ranger.better", "SL.ksvm.better","SL.glm","SL.qda","SL.mean"))
stack_trainY <- p3_trainY
stack_train <- p3_train
stack_train$p3_trainY <- NULL
#Get 5 fold CV estimate of Risk from superlearner
stack <- SuperLearner(Y = stack_trainY, X = stack_train, family = binomial(), cvControl = list(V = 10),
SL.library = c("SL.ranger.better", "SL.ksvm.better","SL.glm","SL.qda","SL.mean"))
fourNine_result
min(fourNine_result)
fourNine_result[which.min(fourNine_result)]
for (k in 1:length(FN_polySVM)) {
if (FN_polySVM[k] != p3_validYfactored[k]){
print(k) #misclassified:
}
}
p3_validYfactored[371,] #1
p3_validYfactored[371] #1
plot_digit(x = validation_x[371,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[1240] #4
p3_validYfactored[2025] #4
p3_validYfactored[2734] #4
plot_digit(x = validation_x[1240,], bw = FALSE, main = "True Class = 4")
plot_digit(x = validation_x[2025,], bw = FALSE, main = "True Class = 4")
plot_digit(x = validation_x[2734,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[371] #4
plot_digit(x = validation_x[371,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[1240] #4
plot_digit(x = validation_x[1240,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2025] #9
plot_digit(x = validation_x[2025,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2734] #9
plot_digit(x = validation_x[2734,], bw = FALSE, main = "True Class = 4")
plot_digit(x = p3_validX[371,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[371] #4
plot_digit(x = p3_validX[371,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[1240] #4
plot_digit(x = p3_validX[1240,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2025] #9
plot_digit(x = p3_validX[2025,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2734] #9
plot_digit(x = p3_validX[2734,], bw = FALSE, main = "True Class = 4")
plot_digit(x = p3_validX[370,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[371] #4
plot_digit(x = p3_validX[371,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[1240] #4
plot_digit(x = p3_validX[1240,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2025] #9
plot_digit(x = p3_validX[2025,], bw = FALSE, main = "True Class = 4")
p3_validYfactored[2734] #9
plot_digit(x = p3_validX[2734,], bw = FALSE, main = "True Class = 4")
p3_results <- data.frame("digit" = test_y,
"p3_pred" = predict(FN_polySVM_classfier, data=test_x)$predictions)
p3_results <- data.frame("digit" = test_y,
"p3_pred" = predict(FN_polySVM_classfier, newdata=test_x)$predictions)
test <- predict(FN_polySVM_classfier, newdata=test_x)
p3_results <- data.frame("digit" = test_y,
"p3_pred" = as.numeric(predict(FN_polySVM_classfier, newdata=test_x)))
View(test_y)
test_y$label <- as.numeric(predict(FN_polySVM_classfier, newdata=test_x))
View(test_y)
test_y$label <- predict(FN_polySVM_classfier, newdata=test_x)
write.csv(as.matrix(test_y), file='Q3Predictions.csv', row.names=FALSE)
#Factored Data
train_yFactored <- factor(train_y)
train_factored <- data.frame(train_x, train_yFactored)
train_yFactored
View(train_y)
View(train_yFactored)
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
library(mgcv)
library(gbm)
library(xgboost)
library(SuperLearner)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#Factored Data
train_yFactored <- factor(train_y)
View(train_yFactored)
train_yFactored
#Factored Data
train_yFactored <- factor(train_y, levels = 0:9)
train_yFactored
#Factored Data
train_yFactored <- factor(train_y$label)
train_yFactored
View(train_yFactored)
View(p3_trainY)
View(p3_trainYfactored)
train_factored <- data.frame(train_x, train_yFactored)
valid_yFactored <- factor(validation_y$label)
valid_yFactored <- factor(validation_y$label)
valid_factored <- data.frame(validation_x, valid_yFactored)
#MLR
multiLogistic_classifier<- multinom(train_yFactored ~ ., data=train_factored, trace=FALSE)
#MLR
multiLogistic_classifier<- multinom(train_yFactored ~ ., data=train_factored, trace=FALSE)
train_yFactored <- factor(train_y$label)
train_factored <- data.frame(train_x, train_yFactored)
valid_yFactored <- factor(validation_y$label)
valid_factored <- data.frame(validation_x, valid_yFactored)
#MLR
multiLogistic_classifier<- multinom(train_yFactored ~ ., data=train_factored, trace=FALSE)
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
library(mgcv)
library(gbm)
library(xgboost)
library(SuperLearner)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#MLR
multiLogistic_classifier <- multinom(train_yFactored ~ ., data=train_factored, trace=FALSE)
View(train_factored)
#MLR
multiLogistic_classifier <- multinom(train_yFactored ~ ., train_factored, trace=FALSE)
train <- data.frame(train_x, train_y)
#Factored Data
train <- data.frame(train_x, train_y)
train_factored <- factor(train$label)
View(train_factored)
#Factored Data
train_factored <- data.frame(train_x, train_y)
train_factored$label <- factor(train_factored$label)
#MLR
multiLogistic_classifier <- multinom(label ~ ., data=train_factored, trace=FALSE)
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
library(mgcv)
library(gbm)
library(xgboost)
library(dplyr)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
library(mgcv)
library(gbm)
library(xgboost)
library(dplyr)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#Factored Data
train_factored <- train_x
train_factored$train_yFactored <- factor(train_y$label)
valid_factored <- validation_x
valid_factored$test_yFactored <- factor(validation_y$label)
#MLR
multiLogistic_classifier <- nnet::multinom(train_yFactored ~., data = train_factored,
trace = FALSE, MaxNWts = 80000)
multiLog_pred<-predict(multiLogistic_classifier, newdata =valid_factored)
multiLog_oos<- mean(multiLog_pred != valid_factored$test_yFactored)
result <- data.frame("Multinomial LR" = multiLog_oos)
#lasso
lasso_TrainX <- data.matrix(train_x)
lasso_TrainY <- data.matrix(train_y)
lasso_validX <- as.matrix(validation_x)
cv_lasso <- cv.glmnet(x=lasso_TrainX, y=lasso_TrainY, family="multinomial",
control = list(maxit = 100), alpha=1, nfolds=5,
type.measure="mse")
lasso_classifier <- glmnet(x=lasso_TrainX, y=lasso_TrainY, family="multinomial", alpha=1,
lambda=cv_lasso$lambda.min)
lasso <- predict(lasso_classifier, lasso_validX, type= "class")
lasso_oos <- mean(lasso != validation_y)
result$lasso <- lasso_oos
#data prep
train <- data.frame(train_x, "train_y" = train_y$label)
#LDA
LDA_classifier <- lda(train_y ~ ., data=train)
LDA <- predict(LDA_classifier,validation_x)$class
LDA_oos <- mean(LDA != validation_y$label)
result$LDA <- LDA_oos
#QDA
QDA_classifier <- qda(train_y ~ ., data=train)
QDA <- predict(QDA_classifier,validation_x)$class
QDA_oos <- mean(QDA != validation_y$label)
result$QDA <- QDA_oos
# Naive Bayes classifier: KDE naive bayes
#we use KDE since data was high dimensional and has a lot of obs.
naiveBayes_classifier<-naive_bayes(as.character(train$train_y) ~ ., data=train, usekernel=TRUE)
naiveBayes <- predict(naiveBayes_classifier, validation_x, type= "class")
naiveBayes_oos <- mean(naiveBayes != validation_y$label)
result$NaiveBayes <- naiveBayes_oos
#SVM data prep
#subsetted data
set.seed(456)
sam_train_factored <- train_factored %>% group_by(train_yFactored) %>% slice_sample(n=500)
#sam_train_factored$train_yFactored
#valid_factored
#valid_factored$test_yFactored
#polySVM
# to find optimal cost and degree
optimal_cost<-0
optimal_degree<-0
optimal_epe<-1000000
cost_vals <- exp(seq(-3,3,length = 30))
#We set our cost in an exponential way so that the cost we try won't be too high that the model overfits, and there are more cost values between 0 and 1 that we would try. This is because we expect the optimal cost value to fall between 0 and 1 for good generalizability, and we want to test carefully which cost value exactly would be the optimal value through CV. This tuning method applies to polySVM and radialSVM.
for (j in 2:3){ #conventionally 2nd or 3rd degree polynomial would be enough
for(i in 1:length(cost_vals)){
#Train the SVM
svm2 <- ksvm(train_yFactored ~ . , data = sam_train_factored, type = "C-svc", kernel = "polydot",
kpar = list(degree = j), C = cost_vals[i], cross = 5, prob.model = TRUE)
#Extract the 5fold CV est and store
temp <- kernlab::cross(svm2)
if (temp<optimal_epe){
optimal_epe<-temp
optimal_cost<-cost_vals[i]
optimal_degree<-j
}
}
}
# finalized model
polySVM_classfier <- ksvm(train_yFactored ~ . , data = sam_train_factored, type = "C-svc",
kernel = "polydot", kpar = list(degree = optimal_degree), C = optimal_cost,
cross = 5, prob.model = TRUE)
polySVM <- predict(polySVM_classfier, newdata = valid_factored, type = "response")
polySVM_oos<- mean(polySVM != valid_factored$train_yFactored)
result$polySVM <- polySVM_oos
#radialSVM
# to find optimal cost
optimal_cost<-0
optimal_degree<-0
optimal_epe<-1000000
#Create a vector of potential C values
cost_vals <- exp(seq(-3,3,length = 30))
for(i in 1:length(cost_vals)){
#Train the SVM
svm3 <- ksvm(train_yFactored ~ . , data = sam_train_factored, type = "C-svc", kernel = "rbfdot",
C = cost_vals[i], cross = 5, prob.model = TRUE)
#Extract the 5fold CV est and store
temp <- kernlab::cross(svm3)
if (temp<optimal_epe){
optimal_epe<-temp
optimal_cost<-cost_vals[i]
}
}
# finalized model
radialSVM_classfier <- ksvm(train_yFactored ~ . , data = sam_train_factored, type = "C-svc",
kernel = "rbfdot", C = optimal_cost, cross = 5, prob.model = TRUE)
radialSVM <- predict(radialSVM_classfier, newdata = valid_factored, type = "response")
radialSVM_oos<- mean(radialSVM != valid_factored$train_yFactored)
result$radialSVM <- radialSVM_oos
#tree methods(bagging, random forest, probability trees, boosted trees)
#data: y-var will also be factored.
#train_factored
#train_factored$train_yFactored
#valid_factored
#valid_factored$test_yFactored
#Bagging
bagging_classifier <- ranger(train_yFactored ~ . , data = train_factored, mtry =
ncol(p3_trainFactored) - 1, num.trees = 1000)
bagging <- predict(bagging_classifier, data = valid_factored)$predictions
bagging_oos<- mean(bagging != valid_factored$train_yFactored)
result$Bagging <- bagging_oos
#Random Forest
optimal_varNum<-0
optimal_treeNum<-0
optimal_oob<-100000000
varNum <- c(2:8, 20, 60, 100) #too many var would be like bagging. but considering the high dimentionality of our x_train dataset, we decided to try a couple below 100.
for (i in 1:length(varNum)){
rfMod<-ranger(train_yFactored ~ . , data = train_factored, num.trees = 1000,
importance = "permutation", mtry = varNum[i], classification = TRUE)
temp_oob<-rfMod$prediction.error
if (temp_oob < optimal_oob){
optimal_oob<-temp_oob
optimal_varNum<-i
}
}
RF_classifier<-ranger(train_yFactored ~ . , data = train_factored,
num.trees = 1000, importance = "permutation",
mtry = varNum[optimal_varNum], classification = TRUE)
RF <- predict(RF_classifier, data = valid_factored)$predictions
RF_oos<- mean(RF != valid_factored$train_yFactored)
result$RF <- RF_oos
#Probability Trees
optimal_varNum<-0
optimal_treeNum<-0
optimal_oob<-100000000
varNum <- c(2:8, 20, 60, 100)
treeNum <- c(1000,2000) #we wanted to tune treeNum too but don't want to spend too much time
for (i in 1:length(varNum)){
for (j in 1:2){
probTMod<-ranger(train_yFactored ~ . , data = train_factored, num.trees = treeNum[j],
importance = "permutation", probability = TRUE, mtry = varNum[i],
classification = TRUE)
temp_oob<-probTMod$prediction.error
if (temp_oob < optimal_oob){
optimal_oob<-temp_oob
optimal_varNum<-i
optimal_treeNum<-j
}
}
}
# finalized model
probT_classifier<-ranger(train_yFactored ~ . , data = train_factored,
num.trees = treeNum[optimal_treeNum], importance = "permutation",
probability = TRUE, mtry = varNum[optimal_varNum], classification = TRUE)
probT <- predict(probT_classifier, data = valid_factored)$predictions
probTree <- c()
for (i in 1:15000){
if (probT[i,1] > probT[i,2]){
probTree[i] = 4
}
else{
probTree[i] = 9
}
}
probTree <- factor(probTree)
probT_oos<- mean(probTree != valid_factored$train_yFactored)
result$ProbabilityTrees <- probT_oos
result
polySVM_oos<- mean(polySVM != valid_factored$valid_yFactored)
result$polySVM <- polySVM_oos
result
valid_factored <- validation_x
valid_factored$valid_yFactored <- factor(validation_y$label)
polySVM_oos<- mean(polySVM != valid_factored$valid_yFactored)
result$polySVM <- polySVM_oos
result
radialSVM_oos<- mean(radialSVM != valid_factored$valid_yFactored)
result$radialSVM <- radialSVM_oos
RF_oos<- mean(RF != valid_factored$valid_yFactored)
result$RF <- RF_oos
probT_oos<- mean(probTree != valid_factored$valid_yFactored)
probT <- predict(probT_classifier, data = valid_factored)$predictions
probTree <- c()
for (i in 1:15000){
if (probT[i,1] > probT[i,2]){
probTree[i] = 4
}
else{
probTree[i] = 9
}
}
probTree <- factor(probTree)
probT
View(probT)
probT[1,]
which.max(probT[1,])
probTree <- c()
for (i in 1:15000){
probTree[i] <- which.max(probT[i,])
}
View(probTree)
for (i in 1:15000){
probTree[i] <- which.max(probT[i,]) -1
}
probTree <- factor(probTree)
probT_oos<- mean(probTree != valid_factored$valid_yFactored)
result$ProbabilityTrees <- probT_oos
result
result
fourNine_result
x_split
x_split <- seq(1,27500,2500)
x_split
result
polySVM_classfier
test_y$label <- predict(polySVM_classfier, newdata=test_x, type = "response")
View(test_y)
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab) #KSVM
library(MASS) #QDA
library(nnet) #MultiNom
library(FNN)
library(splitTools)
library(ranger)
library(glmnet) #Ridge&LASSO
library(naivebayes)
library(mgcv) #GAM
library(gbm)
library(xgboost)
library(dplyr)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
test_y$label <- predict(polySVM_classfier, newdata=test_x, type = "response")
write.csv(as.matrix(test_y), file='Q5Predictions.csv', row.names=FALSE)
polySVM
optimal_degree
polySVM_classfier
