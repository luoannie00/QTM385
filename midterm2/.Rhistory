p2_validX <- validation_x[1:3000,]
p2_validY <- validation_y[1:3000,]
tail(p2_validY)
validation_y[3001,]
p2_trainY <- train_y[1:5000]
p2_trainY <- train_y[1:5000,]
p2_train <- data.frame(p2_trainX, p2_trainY)
View(p2_train)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'))
predict(p2p1_logistic, type='response', newdata=p2_train)
# 1) training misclassification rate
logistic_pred<-predict(p2p1_logistic, newdata = p2_train, type = "response")
tail(logistic_pred)
for (i in 1:nrow(p2_trainX)) {
if (logistic_pred[i] > 0.5) {
logistic_pred[i] <- 1
}
else {
logistic_pred[i] <- 0
}
}
logistic_pred
tail(logistic_pred)
logistic_pred[2500]
logistic_pred[2501]
#predicted classification
logistic_pred<-predict(p2p1_logistic, newdata = p2_train, type = "class")
#predicted classification
logistic_pred<-predict(p2p1_logistic, newdata = p2_train, type = "link")
head(logistic_pred)
tail(logistic_pred)
#predicted classification
logistic_pred<-predict(p2p1_logistic, newdata = p2_train, type = "response")
#logistic regression model
p2_train <- data.frame(p2_trainX, p2_trainY)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'))
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#logistic regression model
p2_train <- data.frame(p2_trainX, p2_trainY)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'))
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
kf_misclass <- c()
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#predicted classification
if (logistic_cv_pred[i] > 0.5) {
logistic_cv_pred[i] <- 1
}
else {
logistic_cv_pred[i] <- 0
}
#Proportion Misclassified
kf_misclass[i] <- mean(logistic_cv_pred != p2_train[-folds[[i]],]$p2_trainY)
}
p2p1_epe<-mean(kf_misclass)
p2p1_epe
kf_misclass
length(folds)
folds
length(logistic_cv_pred)
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
kf_misclass <- c()
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#predicted classification
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
#Count of Misclassifications
if (logistic_cv_pred[j] != p2_train[-folds[[i]],]$p2_trainY[j])
}
p2_train[-folds[[1]],]$p2_trainY[500]
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
kf_misclass <- c()
countMs = 0
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#predicted classification
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
#Count of Misclassifications
if (logistic_cv_pred[j] != p2_train[-folds[[i]],]$p2_trainY[j]){
++countMs
}
}
}
for(i in 1:length(folds)){
for(i in 1:length(folds)){
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#predicted classification
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[j] != p2_train[-folds[[i]],]$p2_trainY[j]){
countMs[i] = countMs[i] + 1
}
}
}
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#predicted classification
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[j] != p2_train[-folds[[i]],]$p2_trainY[j]){
countMs[i] = countMs[i] + 1
}
}
}
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs[i] = countMs[i] + 1
}
}
}
countMs
p2_trainX <- train_x[1:5000,]
p2_trainY <- train_y[1:5000,]
p2_validX <- validation_x[1:3000,]
p2_validY <- validation_y[1:3000,]
#logistic regression model
p2_train <- data.frame(p2_trainX, p2_trainY)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'))
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#logistic regression model
p2_train <- data.frame(p2_trainX, p2_trainY)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'))
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
kf_misclass <- c()
countMs <- c()
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs[i] = countMs[i] + 1
}
}
}
p2p1_epe<-mean(kf_misclass)
p2p1_epe
countMs
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs[i] = countMs[i] + 1
}
else {
count[i] = 0
}
}
}
for(i in 1:length(folds)){
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs[i] = countMs[i] + 1
}
else {
countMs[i] = 0
}
}
}
countMs
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[1]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[1]],], type = "response")
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
logistic_cv_pred
p2_train[-folds[[i]],]$p2_trainY
p2_train[-folds[[1]],]$p2_trainY[266]
p2_train[-folds[[1]],]$p2_trainY[265]
p2_train[-folds[[1]],]$p2_trainY[267]
logistic_cv_pred[266]
mis_rate <- c()
for(i in 1:length(folds)){
countMs = 0
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs = countMs + 1
}
}
mis_rate[i] <- countMs / length(logistic_cv_pred)
}
mis_rate
p2p1_epe<-mean(mis_rate)
p2p1_epe
mis_rate <- c()
countMs = 0
logistic_valid <- predict(p2p1_logistic, newdata = p2_validX, type = "response")
#classify predictions
for (j in 1:length(logistic_valid)){
if (logistic_valid[j] > 0.5) {
logistic_valid[j] <- 1
}
else {
logistic_valid[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_valid)) {
if (logistic_valid[k] != p2_validY[k]){
countMs = countMs + 1
}
}
mis_rate[i] <- countMs / length(logistic_valid)
p2p1_oos<-mean(mis_rate)
p2p1_oos
mis_rate <- countMs / length(logistic_valid)
p2p1_oos<-mean(mis_rate)
p2p1_oos
logistic_valid
length(logistic_valid)
logistic_valid[1500]
logistic_valid[1501]
length(mis_rate)
p2p1_oos <- countMs / length(logistic_valid)
p2p1_oos #0.002
#oos
countMs = 0
logistic_valid <- predict(p2p1_logistic, newdata = p2_validX, type = "response")
#classify predictions
for (j in 1:length(logistic_valid)){
if (logistic_valid[j] > 0.5) {
logistic_valid[j] <- 1
}
else {
logistic_valid[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_valid)) {
if (logistic_valid[k] != p2_validY[k]){
countMs = countMs + 1
}
}
p2p1_oos <- countMs / length(logistic_valid)
p2p1_oos #0.002
countMs
#Count of Misclassifications
for (k in 1:length(logistic_valid)) {
if (logistic_valid[k] != p2_validY[k]){
print(k)
countMs = countMs + 1
}
}
validation_y[271,] #0
plot_digit(x = validation_x[271,], bw = FALSE, main = "True Class = 0")
validation_y[2203,] #0
validation_y[2311,] #0
validation_y[1057,] #0
countMs #there are 6 misclassifications: 271, 1057, 2203, 2259, 2311, 2555
validation_y[271,] #0
plot_digit(x = validation_x[271,], bw = FALSE, main = "True Class = 0")
validation_y[1057,] #0
plot_digit(x = validation_x[1057,], bw = FALSE, main = "True Class = 0")
validation_y[2203,] #1
plot_digit(x = validation_x[2203,], bw = FALSE, main = "True Class = 1")
validation_y[2311,] #1
plot_digit(x = validation_x[2311,], bw = FALSE, main = "True Class = 1")
#logistic regression model
p2_train <- data.frame(p2_trainX, p2_trainY)
p2p1_logistic <- glm(data=p2_train,
formula = p2_trainY ~ .,
family = binomial(link='logit'),
control = list(maxit = 100))
#in-sample EPE
folds <- create_folds(seq(1,nrow(p2_train)), k = 10, type = "basic")
mis_rate <- c()
for(i in 1:length(folds)){
countMs = 0
logistic_cv <- glm(p2_trainY ~ ., data=p2_train[folds[[i]],], trace=FALSE)
logistic_cv_pred <- predict(logistic_cv, newdata = p2_train[-folds[[i]],], type = "response")
#classify predictions
for (j in 1:length(logistic_cv_pred)){
if (logistic_cv_pred[j] > 0.5) {
logistic_cv_pred[j] <- 1
}
else {
logistic_cv_pred[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_cv_pred)) {
if (logistic_cv_pred[k] != p2_train[-folds[[i]],]$p2_trainY[k]){
countMs = countMs + 1
}
}
mis_rate[i] <- countMs / length(logistic_cv_pred)
}
p2p1_epe<-mean(mis_rate)
p2p1_epe #0.0034
#oos
countMs = 0
logistic_valid <- predict(p2p1_logistic, newdata = p2_validX, type = "response")
#classify predictions
for (j in 1:length(logistic_valid)){
if (logistic_valid[j] > 0.5) {
logistic_valid[j] <- 1
}
else {
logistic_valid[j] <- 0
}
}
#Count of Misclassifications
for (k in 1:length(logistic_valid)) {
if (logistic_valid[k] != p2_validY[k]){
print(k) #misclassified: 271, 1057, 2203, 2259, 2311, 2555
countMs = countMs + 1
}
}
p2p1_oos <- countMs / length(logistic_valid)
p2p1_oos #0.002
p2p2_trainX <- data.matrix(p2_trainX)
p2p2_trainY <- data.matrix(p2_trainY)
View(p2p2_trainY)
#scientific lambda
p2_cv_lasso <- cv.glmnet(x=p2p2_trainX, y=p2p2_trainY, family=binomial(link='logit'),
control = list(maxit = 100), alpha=1, nfolds=10,
type.measure="mse")
library(ggplot2)
library(tidyverse)
library(data.table)
library(kernlab)
library(MASS)
library(nnet)
library(FNN)
library(splitTools)
library(ranger)
library(glmnet)
library(naivebayes)
#rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#scientific lambda
p2_cv_lasso <- cv.glmnet(x=p2p2_trainX, y=p2p2_trainY, family=binomial(link='logit'),
control = list(maxit = 100), alpha=1, nfolds=10,
type.measure="mse")
View(p2_cv_lasso)
#scientific lambda
p2_cv_lasso <- cv.glmnet(x=p2p2_trainX, y=p2p2_trainY, family="binomial",
control = list(maxit = 100), alpha=1, nfolds=10,
type.measure="mse")
View(p2_cv_lasso)
p2_cv_lasso[["call"]]
p2_lasso <- glmnet(x=p2p2_trainX, y=p2p2_trainY, family="binomial", alpha=1,
lambda=p2_cv_lasso$lambda.min)
#our chosen value of lambda is
p2_cv_lasso$lambda.min
p2_lasso$beta
cf1 <- c()
cf2 <- c()
cf1 <- c()
cf2 <- c()
for (i in 1:59) {
cf1 <- append(cf1, rownames(p2_lasso$beta)[i])
cf2 <- append(cf2, unname(p2_lasso$beta)[i])
}
cf <- data.frame(cf1, cf2)
ggplot(data=cf, aes(x=cf1, y=cf2)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
p2_corr <- c()
for (i in 1:length(p2_lasso$beta)){
if (p2_lasso$beta[i] > 0) {
p2_corr[i] = 1
}
else if (p2_lasso$beta[i] < 0) {
p2_corr[i] = -1
}
else {
p2_corr[i] = 0
}
}
