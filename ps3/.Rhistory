lm_pred_metrics <- function(fit_model) {
LOOCV <- mean((fit_model$residuals / (1-hatvalues(fit_model)))^2)
return (LOOCV)
}
lm_pred_metrics(p2p1_m) #LOOCV is 0.2343854
#plot
cf <- coef(summary(p2p1_m, complete=TRUE))
cf <- data.frame(rownames(cf), cf)
ggplot(data=cf, aes(x=rownames.cf., y=Estimate)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
#subset of important predictors
p2p1_imp_pred <- o_train %>% select(seasonSeason.3, seasonSeason.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
#important predictors model
p2p1_imp_pred_m <- lm(imdb_rating ~ ., data=p2p1_imp_pred)
#LOOCV
lm_pred_metrics(p2p1_imp_pred_m) #LOOCV is 0.2543553
p2p2_pred <- data.matrix(o_train[,-38])
p2p2_out <- data.matrix(o_train$imdb_rating)
#100 possible values of lambda
p2p2_ridgem <- glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, nlambda=100)
print(p2p2_ridgem)
p2p2_cv_ridgem <- cv.glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, nfolds=10, type.measure="mse")
plot(p2p2_cv_ridgem)
print(p2p2_cv_ridgem)
p2p2_optimal_ridgem <- glmnet::glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, lambda=p2p2_cv_ridgem$lambda.min)
#plot
cf1 <- c()
cf2 <- c()
for (i in 1:37) {
cf1 <- append(cf1, rownames(p2p2_optimal_ridgem$beta)[i])
cf2 <- append(cf2, unname(p2p2_optimal_ridgem$beta)[i])
}
cf <- data.frame(cf1, cf2)
ggplot(data=cf, aes(x=cf1, y=cf2)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
p2p3_pred <- data.matrix(o_train[,-38])
p2p3_out <- data.matrix(o_train$imdb_rating)
#100 possible values of lambda
p2p3_lassom <- glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, nlambda=100)
#print(p2p3_lassom)
p2p3_cv_lassom <- cv.glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, nfolds=10, type.measure="mse")
plot(p2p3_cv_lassom)
print(p2p3_cv_lassom)
#0.03343 is the initial p2p3_cv_lassom$lambda.min we get
p2p3_optimal_lassom <- glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, lambda=p2p3_cv_lassom$lambda.min)
#plot
cf1 <- c()
cf2 <- c()
for (i in 1:37) {
cf1 <- append(cf1, rownames(p2p3_optimal_lassom$beta)[i])
cf2 <- append(cf2, unname(p2p3_optimal_lassom$beta)[i])
}
cf <- data.frame(cf1, cf2)
ggplot(data=cf, aes(x=cf1, y=cf2)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
data.frame(
epe_full_lm = lm_pred_metrics(p2p1_m),
epe_subset_lm = lm_pred_metrics(p2p1_imp_pred_m),
epe_optimal_ridge = min(p2p2_cv_ridgem$cvm),
epe_optimal_lasso = min(p2p3_cv_lassom$cvm))
#delete variable episode_name
o_test <- o_test %>% select(-episode_name)
#split variable season into 9 variables
dummy_o_test <- caret::dummyVars("~.", data=o_test)
o_test <- data.frame(predict(dummy_o_test, newdata=o_test))
p2p4_pred_mat <- as.matrix(o_test[,-38])
p2p4_pred_df_full <- o_test[,-38]
p2p4_pred_df_imp <- o_test %>% select(seasonSeason.3, seasonSeason.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
#predictions
o_test$full_lm <- predict(p2p1_m, newdata=p2p4_pred_df_full)
o_test$subset_lm <- predict(p2p1_imp_pred_m, newdata=p2p4_pred_df_imp)
o_test$optimal_ridge <- predict(p2p2_optimal_ridgem, newx=p2p4_pred_mat)
o_test$optimal_lasso <- predict(p2p3_optimal_lassom, newx=p2p4_pred_mat)
#mse comparison
data.frame(
mse_full_lm = mse(o_test$imdb_rating, o_test$full_lm),
mse_subset_lm = mse(o_test$imdb_rating, o_test$subset_lm),
mse_optimal_ridge = mse(o_test$imdb_rating, o_test$optimal_ridge),
mse_optimal_lasso = mse(o_test$imdb_rating, o_test$optimal_lasso))
#initial recoding: use c_train_q4 moving on for consistence
c_train_q4 <- c_train
c_train_q4$Outstate <- log(c_train$Outstate)
approachPlot <- qplot(x=S.F.Ratio, y=Outstate, data=c_train_q4, geom=c("point","smooth"), ylab="out of state tuition", xlab="student/faculty ratio")
approachPlot
# It looks quite linear, but could also be a second/third degree polynomial relationship. Compare the first smooth graph with the second one plotting in linear model, we can see that the relationship has a linear trend.
lmApprochPlot <- qplot(x=S.F.Ratio, y=Outstate, data=c_train_q4, geom=c("point","smooth"), method="lm", ylab="out of state tuition", xlab="student/faculty ratio")
lmApprochPlot
# we reuse the function from problem set 2 for the wealth of non-simulation based estimates of the expected prediction error to make this decision
lm_pred_metrics <- function(fit_model) {
#log-likelihood
N <- length(fit_model$residuals)
sig <- sigma(fit_model)
res <- fit_model$residuals
ll <- -N/2*log10(2*pi) - N/2*log10(sig^2) - 1/(2*sig^2)*sum(res^2)
#AIC
d <- length(fit_model$coefficients) + 1
AIC <- -2*ll + 2*(d)
#BIC
BIC <- -2*ll + d*log10(N)
#LOOCV
LOOCV <- (res[1] / (1-hatvalues(fit_model)[1]))^2
if (N>=2){
for (i in 2:N){
LOOCV <- LOOCV + (res[i] / (1-hatvalues(fit_model)[i]))^2
}
}
LOOCV_final <- LOOCV / N
return(c("AIC"=AIC, "BIC"=BIC, "LOOCV"=LOOCV_final))
}
p4p1_model_1 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,1))
p4p1_model_2 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,2))
p4p1_model_3 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,3))
p4p1_model_4 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,4))
p4p1_model_5 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,5))
p4p1_model_6 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,6))
p4p1_model_7 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,7))
p4p1_model_8 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,8))
p4p1_model_9 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,9))
p4p1_model_10 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,10))
p4p1_df <- t(cbind(lm_pred_metrics(p4p1_model_1), lm_pred_metrics(p4p1_model_2), lm_pred_metrics(p4p1_model_3), lm_pred_metrics(p4p1_model_4), lm_pred_metrics(p4p1_model_5), lm_pred_metrics(p4p1_model_6), lm_pred_metrics(p4p1_model_7), lm_pred_metrics(p4p1_model_8), lm_pred_metrics(p4p1_model_9), lm_pred_metrics(p4p1_model_10)))
num <- c(1:10)
p4p1_df <- data.frame(num, p4p1_df)
#plot LOOCV for various degree of polynomial
ggplot(data=p4p1_df) +
geom_point(aes(x=num, y=LOOCV.1)) +
geom_line(aes(x=num, y=LOOCV.1)) +
xlab("degree polynomial") + ylab('LOOCV') +
theme_bw()
# We use LOOCV as our measure of EPE and find that third order of global polynomial that minimizes EPE. We choose LOOCV as there is less worry about bias and variance than other approaches and it's asymptotically unbiased for the  the EPE.From the graph above, we could see that the LOOCV reaches minimum for degree polynomial=3.
#optimal polynomial model
#train the model with third degree of polynomial
optimalPolyModel <- lm(data=c_train_q4, Outstate ~ poly(S.F.Ratio,3))
polyPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,
predOutState=optimalPolyModel$fitted.values,
originalOutState=c_train_q4$Outstate)
#plot our polynomial model
polyPredResultPlot <- ggplot(data=polyPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
polyPredResultPlot
#natural spline(cubic)
#find the optimal df with our measure of EPE
p4_1_num <- seq(1,20,1)
p4_1_aic <- c()
p4_1_bic <- c()
p4_1_loocv <- c()
for (i in 1:20) {
cubicSpline <- lm(Outstate ~ ns(S.F.Ratio,df=i), data=c_train_q4)
tempCheck <- unname(lm_pred_metrics(cubicSpline))
p4_1_aic <- append(p4_1_aic, tempCheck[1])
p4_1_bic <- append(p4_1_bic, tempCheck[2])
p4_1_loocv <- append(p4_1_loocv, tempCheck[3])
}
p4_1_dat <- data.frame(p4_1_num, p4_1_aic, p4_1_bic, p4_1_loocv)
#plot how each df perform with each measure of EPE
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_aic)) +
geom_line(aes(x=p4_1_num, y=p4_1_aic)) +
xlab('df') + ylab('aic') +
theme_bw()
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_bic)) +
geom_line(aes(x=p4_1_num, y=p4_1_bic)) +
xlab('df') + ylab('bic') +
theme_bw()
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_loocv)) +
geom_line(aes(x=p4_1_num, y=p4_1_loocv)) +
xlab('df') + ylab('loocv') +
theme_bw()
#optimal Natural Spline model
optimalCubicModel <- lm(Outstate ~ ns(S.F.Ratio,df=4), data=c_train_q4)
nsPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,
predOutState=optimalCubicModel$fitted.values,
originalOutState=c_train_q4$Outstate)
predResultPlot <- ggplot(data=nsPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
predResultPlot
#optimal smoothing spline model
optimalSSModel <- smooth.spline(x=c_train_q4$S.F.Ratio, y=c_train_q4$Outstate)
ssPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,predOutState=predict(optimalSSModel, x=c_train_q4$S.F.Ratio), originalOutState=c_train_q4$Outstate)
predResultPlot <- ggplot(data=ssPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState.y, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
predResultPlot
#Comparing  the optimal model we got through cubic natural spline and smoothing spline, we can see that optimal smoothing spline model goes more smoothly than the natural spline one, especially on the left end where S.F.ratio smaller than 15.
#recode testing dataframe
c_test_q4 <- c_test
c_test_q4$Outstate <- log(c_test$Outstate)
#train three optimal models and calculate mse
test_poly_MSE = mse(predict(optimalPolyModel,newdata=c_test_q4), c_test_q4$Outstate)
test_ns_MSE = mse(predict(optimalCubicModel,newdata=c_test_q4), c_test_q4$Outstate)
test_ss_MSE = mse(predict(optimalSSModel, x=c_test_q4$S.F.Ratio)$y, c_test_q4$Outstate)
table<-data.frame(polyTestResult=test_poly_MSE,
naturalSplineResult=test_ns_MSE,
smoothingSplineResult=test_ss_MSE)
table
#From the table above, we can see that the natural cubic spline model and the smoothing spline model perform similarly well in terms of mse, whereas the third order polynomial model doesn't. It is because the natural cubic spline model and the smoothing spline model divide the dataset into partitions and fit linear models to each partition, which is superior than the third order polynomial model that treats the entire training dataset as one entity.
# set things as matrix
lasso_predictor <- data.matrix(c_train_q4[,-9])
lasso_outcome <- data.matrix(c_train_q4$Outstate)
c_lasso_cv <- cv.glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, nfolds=10, type.measure="mse")
print(c_lasso_cv)
plot(c_lasso_cv)
optimalLambda<-c_lasso_cv$lambda.min
smallVarLambda<-c_lasso_cv$lambda.1se
c_lasso_optimal <- glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, lambda=optimalLambda)
#there are 13 variables in our optimal list (shown below)
variableList<-c_lasso_optimal$beta
variableList
#We decide to go with the second approach
# From the plot() and cv function in part two, we alreay know the min mse Lambda(optimalLambda) and largest value of lambda that error within 1 standard error of the min.(smallVarLambda) as the following:
optimalLambda<-c_lasso_cv$lambda.min
smallVarLambda<-c_lasso_cv$lambda.1se
# models trained with these two lambda values
c_lasso_optimal <- glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, lambda=optimalLambda)
c_lasso_largeLambda <- glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, lambda=smallVarLambda)
# print the included predictors
c_lasso_optimal$beta
c_lasso_largeLambda$beta
#In conclusion, we pick the following 5 predictors:
#Private/S.F.Ratio/PhD/perc.alumni/Grad.Rate
c_test_q4_selected<-data.frame(Outstate=c_test_q4$Outstate,
Private=c_test_q4$Private,
S.F.Ratio=c_test_q4$S.F.Ratio,
PhD=c_test_q4$PhD,
perc.alumni=c_test_q4$perc.alumni,
Grad.Rate=c_test_q4$Grad.Rate)
c_train_q4_selected<-data.frame(Outstate=c_train_q4$Outstate,
Private=c_train_q4$Private,
S.F.Ratio=c_train_q4$S.F.Ratio,
PhD=c_train_q4$PhD,
perc.alumni=c_train_q4$perc.alumni,
Grad.Rate=c_train_q4$Grad.Rate)
#try to build model with GAM
# if we include all variables in smooth, the model and gcv is:
fullGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) +
s(Grad.Rate),data=c_train_q4_selected,family = gaussian())
fullGamGcv<-fullGam$gcv.ubre.dev
print("The gcv for optimal model is")
fullGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+S.F.Ratio + PhD + perc.alumni +Grad.Rate,
data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-lm(Outstate ~ Private+S.F.Ratio + PhD + perc.alumni +Grad.Rate,
data=c_train_q4_selected)
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
testGam
testGam
View(lm_pred_metrics)
lm_pred_metrics(testGam)
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ te(Private)+te(S.F.Ratio) + te(PhD) + te(perc.alumni) +te(Grad.Rate),
data=c_train_q4_selected,family = gaussian())
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+te(S.F.Ratio) + te(PhD) + te(perc.alumni) +te(Grad.Rate),
data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
fullLinearM<-lm(Outstate~.,data=c_train_q4)
c_train_q4
lm_pred_metrics(fullLinearM)
fullLinearM<-lm(Outstate~. ,data=c_train_q4)
lm_pred_metrics(fullLinearM)
fullLinearM
View(c_train)
df<-data.matrix(c_test_q4[,-19])
fullLinearM<-lm(Outstate~. ,data=df)
df<-frame(c_test_q4[,-19])
df<-data.frame(c_test_q4[,-19])
fullLinearM<-lm(Outstate~. ,data=df)
fullLinearM
lm_pred_metrics(fullLinearM)
df<-data.frame(c_train_q4[,-19])
fullLinearM<-lm(Outstate~. ,data=df)
lm_pred_metrics(fullLinearM)
mse(predict(fullLinearM,newdata=c_test_q4[,-19]),c_test_q4$Outstate)
testGam
lm_pred_metrics(fullLinearM)
#GAM model:optGAMModel
GamPredmodel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
#LASaO model: c_lasso_optimal
lasso_predictor <- data.matrix(c_test_q4[,-9])
mse_Lasoo<-mse(c_test_q4$Outstate,predict(c_lasso_optimal,newx=lasso_predictor))
p4p4_mseOutput<-data.frame(GAM_mse=mse_GAM,Lasoo_mse=mse_Lasoo)
p4p4_mseOutput
#If we take mse data below as reference, Lasso performs better than our GAM model.
summary(GamPredmodel)
View(lm_pred_metrics)
tempM<-gam(Outstate ~ Private+s(S.F.Ratio) + s(perc.alumni) + s(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(tempM,c_test_q4))
mse_GAM
#GAM model:optGAMModel
GamPredmodel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
#LASaO model: c_lasso_optimal
lasso_predictor <- data.matrix(c_test_q4[,-9])
mse_Lasoo<-mse(c_test_q4$Outstate,predict(c_lasso_optimal,newx=lasso_predictor))
p4p4_mseOutput<-data.frame(GAM_mse=mse_GAM,Lasoo_mse=mse_Lasoo)
p4p4_mseOutput
#If we take mse data below as reference, Lasso performs better than our GAM model.
GamPredmodel<-gam(Outstate ~ Private+ ns(S.F.Ratio) + ns(PhD) + ns(perc.alumni) + ns(Grad.Rate)+ns(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
mse_GAM
#GAM model:optGAMModel
GamPredmodel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
#LASaO model: c_lasso_optimal
lasso_predictor <- data.matrix(c_test_q4[,-9])
mse_Lasoo<-mse(c_test_q4$Outstate,predict(c_lasso_optimal,newx=lasso_predictor))
p4p4_mseOutput<-data.frame(GAM_mse=mse_GAM,Lasoo_mse=mse_Lasoo)
p4p4_mseOutput
#If we take mse data below as reference, Lasso performs better than our GAM model.
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+te(S.F.Ratio) + te(PhD) + te(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + te(PhD) + te(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + te(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + te(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + ti(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if try to apply te() or s() through all
testGam<-gam(Outstate ~ Private+ti(S.F.Ratio) + ti(PhD) + ti(perc.alumni) +te(Grad.Rate),data=c_train_q4_selected,family = gaussian())
testGamGcv<-testGam$gcv.ubre.dev
testGamGcv
#if we want to include one interaction term w ti()
tiMinGcv<-100
#summary()
for (i in 3:6){
for (j in 3:6){
if (i==j){
break
}
df<-data.frame(c_train_q4_selected[i],c_train_q4_selected[j],c_train_q4_selected[1])
names(df)[1] <- "x1"
names(df)[2] <- "x2"
names(df)[3] <- "y"
tempModel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+ti(df$x1,df$x2),
data=c_train_q4_selected,
family = gaussian())
tempGcv<-tempModel$gcv.ubre.dev
if (tiMinGcv>tempGcv){
tiMinGcv<-tempGcv
tinum1<-i
tinum2<-j
bestTiModel<-tempModel
}
}
}
#plot(bestSModel,pages=1)
print("The gcv for optimal model is")
tiMinGcv
print("The interaction is between:")
names(c_train_q4_selected[tinum1])
names(c_train_q4_selected[tinum2])
#if we want to include one interaction term w s()
sMinGcv<-100
#summary()
for (i in 3:6){
for (j in 3:6){
if (i==j){
break
}
df<-data.frame(c_train_q4_selected[i],c_train_q4_selected[j],c_train_q4_selected[1])
names(df)[1] <- "x1"
names(df)[2] <- "x2"
names(df)[3] <- "y"
tempModel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(df$x1,df$x2),
data=c_train_q4_selected,
family = gaussian())
tempGcv<-tempModel$gcv.ubre.dev
if (sMinGcv>tempGcv){
sMinGcv<-tempGcv
snum1<-i
snum2<-j
bestSModel<-tempModel
}
}
}
#plot(bestSModel,pages=1)
print("The gcv for optimal model is")
sMinGcv
print("The interaction is between:")
names(c_train_q4_selected[snum1])
names(c_train_q4_selected[snum2])
#if we want to include one interaction term w te() tensor spline
temMinGcv<-100
#summary()
for (i in 3:6){
for (j in 3:6){
if (i==j){
break
}
df<-data.frame(c_train_q4_selected[i],c_train_q4_selected[j],c_train_q4_selected[1])
names(df)[1] <- "x1"
names(df)[2] <- "x2"
names(df)[3] <- "y"
tempModel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+te(df$x1,df$x2),
data=c_train_q4_selected,
family = gaussian())
tempGcv<-tempModel$gcv.ubre.dev
if (temMinGcv>tempGcv){
temMinGcv<-tempGcv
num1<-i
num2<-j
bestTEModel<-tempModel
}
}
}
# result
print("The gcv for optimal model is")
temMinGcv # also the smallest gcv we got so far
print("The interaction is between:")
names(c_train_q4_selected[num1])
names(c_train_q4_selected[num2])
#best Model with one TI(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+ti(perc.alumni,S.F.Ratio)
plot(bestTiModel,pages = 1)
# so we have three optimal models with/without interaction in various formula:
#gcv we got for each model:
gcvSum<-data.frame(fullGamGCV=fullGamGcv,bestTEGCV=temMinGcv ,bestSGCV=sMinGcv)
gcvSum
#best Model with one s(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,Phd)
plot(bestSModel,pages=1)
#fullGam model simply s() on everything
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)
plot(fullGam,pages=1)
#best Model with one TE(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+te(perc.alumni,S.F.Ratio)
plot(bestTEModel,pages=1)
#best Model with one TI(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+ti(perc.alumni,S.F.Ratio)
plot(bestTiModel,pages = 1)
# so we have three optimal models with/without interaction in various formula:
#gcv we got for each model:
gcvSum<-data.frame(fullGamGCV=fullGamGcv,bestTEGCV=temMinGcv ,bestSGCV=sMinGcv,bestTIGcv=tiMinGcv)
gcvSum
#best Model with one s(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,Phd)
plot(bestSModel,pages=1)
#fullGam model simply s() on everything
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)
plot(fullGam,pages=1)
#best Model with one TE(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+te(perc.alumni,S.F.Ratio)
plot(bestTEModel,pages=1)
#best Model with one TI(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+ti(perc.alumni,S.F.Ratio)
plot(bestTiModel,pages = 1)
GamPredmodel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+ti(perc.alumni,S.F.Ratio),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
#LASaO model: c_lasso_optimal
lasso_predictor <- data.matrix(c_test_q4[,-9])
mse_Lasoo<-mse(c_test_q4$Outstate,predict(c_lasso_optimal,newx=lasso_predictor))
p4p4_mseOutput<-data.frame(GAM_mse=mse_GAM,Lasoo_mse=mse_Lasoo)
p4p4_mseOutput
#GAM model:optGAMModel
GamPredmodel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,PhD),data=c_train_q4_selected,family = gaussian())
mse_GAM<-mse(c_test_q4_selected$Outstate,predict.gam(GamPredmodel,c_test_q4))
#LASaO model: c_lasso_optimal
lasso_predictor <- data.matrix(c_test_q4[,-9])
mse_Lasoo<-mse(c_test_q4$Outstate,predict(c_lasso_optimal,newx=lasso_predictor))
p4p4_mseOutput<-data.frame(GAM_mse=mse_GAM,Lasoo_mse=mse_Lasoo)
p4p4_mseOutput
