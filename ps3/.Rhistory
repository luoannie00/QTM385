variableList
#We decide to go with the second approach
# From the plot() and cv function in part two, we alreay know the min mse Lambda(optimalLambda) and largest value of lambda that error within 1 standard error of the min.(smallVarLambda) as the following:
optimalLambda<-c_lasso_cv$lambda.min
smallVarLambda<-c_lasso_cv$lambda.1se
# models trained with these two lambda values
c_lasso_optimal <- glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, lambda=optimalLambda)
c_lasso_largeLambda <- glmnet(x=lasso_predictor, y=lasso_outcome, family="gaussian", alpha=1, lambda=smallVarLambda)
# print the included predictors
c_lasso_optimal$beta
c_lasso_largeLambda$beta
#In conclusion, we pick the following 5 predictors:
#Private/S.F.Ratio/PhD/perc.alumni/Grad.Rate
c_test_q4_selected<-data.frame(Outstate=c_test_q4$Outstate,Private=c_test_q4$Private,S.F.Ratio=c_test_q4$S.F.Ratio,PhD=c_test_q4$PhD,perc.alumni=c_test_q4$perc.alumni,Grad.Rate=c_test_q4$Grad.Rate)
c_train_q4_selected<-data.frame(Outstate=c_train_q4$Outstate,Private=c_train_q4$Private,S.F.Ratio=c_train_q4$S.F.Ratio,PhD=c_train_q4$PhD,perc.alumni=c_train_q4$perc.alumni,Grad.Rate=c_train_q4$Grad.Rate)
smallVarLambda
optimalLambda
#if we want to include one interaction term w te() tensor spline
temMinGcv<-100
#summary()
for (i in 3:6){
for (j in 3:6){
if (i==j){
break
}
df<-data.frame(c_train_q4_selected[i],c_train_q4_selected[j],c_train_q4_selected[1])
names(df)[1] <- "x1"
names(df)[2] <- "x2"
names(df)[3] <- "y"
tempModel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+te(df$x1,df$x2),
data=c_train_q4_selected,
family = gaussian())
tempGcv<-tempModel$gcv.ubre.dev
if (temMinGcv>tempGcv){
temMinGcv<-tempGcv
num1<-i
num2<-j
bestTEModel<-tempModel
}
}
}
# result
print("The gcv for optimal model is")
temMinGcv # also the smallest gcv we got so far
print("The interaction is between:")
names(c_train_q4_selected[num1])
names(c_train_q4_selected[num2])
bestTEModel
summary(bestTEModel)
#if we want to include one interaction term w s()
sMinGcv<-100
#summary()
for (i in 3:6){
for (j in 3:6){
if (i==j){
break
}
df<-data.frame(c_train_q4_selected[i],c_train_q4_selected[j],c_train_q4_selected[1])
names(df)[1] <- "x1"
names(df)[2] <- "x2"
names(df)[3] <- "y"
tempModel<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(df$x1,df$x2),
data=c_train_q4_selected,
family = gaussian())
tempGcv<-tempModel$gcv.ubre.dev
if (sMinGcv>tempGcv){
sMinGcv<-tempGcv
snum1<-i
snum2<-j
bestSModel<-tempModel
}
}
}
#plot(bestSModel,pages=1)
print("The gcv for optimal model is")
sMinGcv
print("The interaction is between:")
names(c_train_q4_selected[snum1])
names(c_train_q4_selected[snum2])
# so we have three optimal models with/without interaction in various formula:
#gcv we got for each model:
gcvSum<-data.frame(fullGamGCV=fullGamGcv,bestTEGCV=temMinGcv ,bestSGCV=sMinGcv)
#try to build model with GAM
# if we include all variables in smooth, the model and gcv is:
fullGam<-gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate),data=c_train_q4_selected,family = gaussian())
fullGamGcv<-fullGam$gcv.ubre.dev
print("The gcv for optimal model is")
fullGamGcv
# so we have three optimal models with/without interaction in various formula:
#gcv we got for each model:
gcvSum<-data.frame(fullGamGCV=fullGamGcv,bestTEGCV=temMinGcv ,bestSGCV=sMinGcv)
gcvSum
#best Model with one s(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,Phd)
plot(bestSModel,pages=1)
#fullGam model simply s() on everything
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)
plot(fullGam,pages=1)
#best Model with one TE(interaction) term
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+te(perc.alumni,S.F.Ratio)
plot(bestTEModel,pages=1)
#gam(Outstate ~ Private+s(S.F.Ratio) + s(PhD) + s(perc.alumni) + s(Grad.Rate)+s(Grad.Rate,Phd)
optGAMModel<-bestSModel
plot(optGAMModel)
#We decide to go with this model as it gives as the relatively low gcv with interactions between Grad.Rate and Phd (somewhat) makes more sense than other models we got.
#The marginal relationship makes sense most of the predictors. For PhD and perc.alumni, it makes sense the functions don't change much while the value of those variable change.For S.F.Ratio, it also makes sense that when the ratio is lower it matters more to out of state tuition.(vice versa for Grad.Rate)
#For 2-predictor spline terms, we could see from the last graph that our optimal model does capture relation that won't be captured by a linear model.
# s(df$x1, df$x2) is s(Grad.Rate,Phd)
summary(optGAMModel)
#The function we got from the first graph above is quite similar with the shape of what we uncovered in part1. It might imply that S.F.Ratio is additive to the GAM model in the way that we structure it.(as we could see in the summary, we have a quite low p-value for S.F.Ratio.)
#recode testing dataframe
c_test_q4 <- c_test
c_test_q4$Outstate <- log(c_test$Outstate)
#train three optimal models and calculate mse
test_poly_MSE = mse(predict(optimalPolyModel,x=c_test_q4$S.F.Ratio),c_test_q4$Outstate)
test_ns_MSE = mse(predict(optimalCubicModel,x=c_test_q4$S.F.Ratio),c_test_q4$Outstate)
ssTestPredResult <- data.frame(predOutState=predict(optimalSSModel, x=c_test_q4$S.F.Ratio),                         originalOutState=c_test_q4$Outstate)
test_ss_MSE = mse(ssTestPredResult$predOutState.y,c_test_q4$Outstate)
table<-data.frame(polyTestResult=test_poly_MSE,naturalSplineResult=test_ns_MSE,smoothingSplineResult=test_ss_MSE)
table
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio)
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio, data = c_train_q4)
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio, data = c_test_q4)
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio, data = c_train_q4)
c_test_q4$Outstate
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio, data = c_train_q4)
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio, data = c_test_q4)
View(optimalPolyModel)
#train three optimal models and calculate mse
test_poly_MSE = mse(predict(optimalPolyModel,x=c_test_q4$S.F.Ratio),c_test_q4$Outstate)
predict(optimalPolyModel,x=c_test_q4$S.F.Ratio)
predict(optimalPolyModel,data=c_test_q4$S.F.Ratio)
predict(optimalPolyModel,data=c_test_q4)
library(ggplot2)
library(data.table)
library(dplyr)
library(Metrics) #rmse(actual, predicted)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
rm(list = ls())
PS1T1 <- read.csv('/Users/annie/Desktop/QTM385/Problem Sets/PS1Train1.csv')
library(ggplot2)
library(data.table)
library(dplyr)
library(Metrics) #rmse(actual, predicted)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
rm(list = ls())
setwd('/Users/annie/Desktop/QTM385/PS1')
PS1T1 <- read.csv('PS1Train1.csv')
PS1T2 <- read.csv('PS1Train2.csv')
ggplot(PS1T1, aes(x=x, y=y)) + geom_point()
ggplot(PS1T2, aes(x=x, y=y)) + geom_point()
OLS1<-lm(y~x, data=PS1T1)
OLS2<-lm(y~x, data=PS1T2)
OLS1_int <- OLS1$coefficients[1]
OLS2_int <- OLS2$coefficients[1]
OLS1_coeff <- OLS1$coefficients[2]
OLS2_coeff <- OLS2$coefficients[2]
RMSE1 <- sqrt(1/200*sum((PS1T1$y-predict(OLS1))^2))
RMSE2 <- sqrt(1/200*sum((PS1T2$y-predict(OLS2))^2))
table_part2 <- data.frame(intercept= c(OLS1_int, OLS2_int),
coefficient = c(OLS1_coeff, OLS2_coeff),
RMSE = c(RMSE1, RMSE2))
ggplot(PS1T1, aes(x=x, y=y)) + geom_point()+
geom_line(size=0.8, aes(x=x,y=predict(OLS1)),color='navy')
ggplot(PS1T2, aes(x=x, y=y)) + geom_point()+
geom_line(size=0.8, aes(x=x,y=predict(OLS2)),color='navy')
predict(lm(y~poly(x,1)
predict(lm(y~poly(x,1), data=PS1T1))
predict(lm(y~poly(x,1), data=PS1T1))
PS1T1$y
predict(optimalPolyModel,newdata=c_test_q4$S.F.Ratio)
library(tidyverse)
library(glmnet)
library(caret)
library(Metrics)
library(splines)
library(mgcv)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#setwd('/Users/billyge/Desktop/Emory Fall 2022/QTM 385-4/problem sets/ps github/ps3')
#setwd('/Users/annie/Desktop/QTM385/QTM350_Github/QTM350 Github/QTM385/ps3')
#rm(list = ls())
c_test <- read.csv('college_test.csv')
c_train <- read.csv('college_train.csv')
o_test <- read.csv('office_test.csv')
o_train <- read.csv('office_train.csv')
#delete variable episode_name
o_train <- o_train %>% select(-episode_name)
#split variable season into 9 variables
dummy_o_train <- caret::dummyVars("~.", data=o_train)
o_train <- data.frame(predict(dummy_o_train, newdata=o_train))
#full model
p2p1_m <- lm(imdb_rating ~ ., data=o_train)
#LOOCV
lm_pred_metrics <- function(fit_model) {
LOOCV <- mean((fit_model$residuals / (1-hatvalues(fit_model)))^2)
return (LOOCV)
}
lm_pred_metrics(p2p1_m) #LOOCV is 0.2343854
#plot
cf <- coef(summary(p2p1_m, complete=TRUE))
cf <- data.frame(rownames(cf), cf)
ggplot(data=cf, aes(x=rownames.cf., y=Estimate)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
#subset of important predictors
p2p1_imp_pred <- o_train %>% select(seasonSeason.3, seasonSeason.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
predict(optimalPolyModel,newdata=c_test_q4$S.F.Ratio)
library(tidyverse)
library(glmnet)
library(caret)
library(Metrics)
library(splines)
library(mgcv)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
#setwd('/Users/billyge/Desktop/Emory Fall 2022/QTM 385-4/problem sets/ps github/ps3')
#setwd('/Users/annie/Desktop/QTM385/QTM350_Github/QTM350 Github/QTM385/ps3')
#rm(list = ls())
c_test <- read.csv('college_test.csv')
c_train <- read.csv('college_train.csv')
o_test <- read.csv('office_test.csv')
o_train <- read.csv('office_train.csv')
#delete variable episode_name
o_train <- o_train %>% select(-episode_name)
#split variable season into 9 variables
dummy_o_train <- caret::dummyVars("~.", data=o_train)
o_train <- data.frame(predict(dummy_o_train, newdata=o_train))
#full model
p2p1_m <- lm(imdb_rating ~ ., data=o_train)
#LOOCV
lm_pred_metrics <- function(fit_model) {
LOOCV <- mean((fit_model$residuals / (1-hatvalues(fit_model)))^2)
return (LOOCV)
}
lm_pred_metrics(p2p1_m) #LOOCV is 0.2343854
#plot
cf <- coef(summary(p2p1_m, complete=TRUE))
cf <- data.frame(rownames(cf), cf)
ggplot(data=cf, aes(x=rownames.cf., y=Estimate)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
#subset of important predictors
p2p1_imp_pred <- o_train %>% select(seasonSeason.3, seasonSeason.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
#optimal polynomial model
#train the model with third degree of polynomial
optimalPolyModel <- lm(c_train_q4$Outstate ~ poly(c_train_q4$S.F.Ratio,3))
library(tidyverse)
library(glmnet)
library(caret)
library(Metrics)
library(splines)
library(mgcv)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
setwd('/Users/annie/Desktop/QTM385/PS3')
rm(list = ls())
c_test <- read.csv('college_test.csv')
c_train <- read.csv('college_train.csv')
o_test <- read.csv('office_test.csv')
o_train <- read.csv('office_train.csv')
#delete variable episode_name
o_train <- o_train %>% select(-episode_name)
#split variable season into 9 variables
dummy_o_train <- caret::dummyVars("~.", data=o_train)
o_train <- data.frame(predict(dummy_o_train, newdata=o_train))
#full model
p2p1_m <- lm(imdb_rating ~ ., data=o_train)
#LOOCV
lm_pred_metrics <- function(fit_model) {
LOOCV <- mean((fit_model$residuals / (1-hatvalues(fit_model)))^2)
return (LOOCV)
}
lm_pred_metrics(p2p1_m) #LOOCV is 0.2343854
#plot
cf <- coef(summary(p2p1_m, complete=TRUE))
cf <- data.frame(rownames(cf), cf)
ggplot(data=cf, aes(x=rownames.cf., y=Estimate)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
#subset of important predictors
p2p1_imp_pred <- o_train %>% select(season.Season.3, season.Season.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
#important predictors model
p2p1_imp_pred_m <- lm(imdb_rating ~ ., data=p2p1_imp_pred)
#LOOCV
lm_pred_metrics(p2p1_imp_pred_m) #LOOCV is 0.2543553
p2p2_pred <- as.matrix(o_train[,-38])
p2p2_out <- as.matrix(o_train$imdb_rating)
#100 possible values of lambda
p2p2_ridgem <- glmnet::glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, nlambda=100)
print(p2p2_ridgem)
p2p2_cv_ridgem <- cv.glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, nfolds=10, type.measure="mse")
plot(p2p2_cv_ridgem)
#min(p2p2_ridgem$lambda)
print(p2p2_cv_ridgem)
p2p2_optimal_ridgem <- glmnet::glmnet(x=p2p2_pred, y=p2p2_out, family="gaussian", alpha=0, lambda=0.74)
#plot
cf1 <- c()
cf2 <- c()
for (i in 1:37) {
cf1 <- append(cf1, rownames(p2p2_optimal_ridgem$beta)[i])
cf2 <- append(cf2, unname(p2p2_optimal_ridgem$beta)[i])
}
cf <- data.frame(cf1, cf2)
ggplot(data=cf, aes(x=cf1, y=cf2)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
p2p3_pred <- as.matrix(o_train[,-38])
p2p3_out <- as.matrix(o_train$imdb_rating)
#100 possible values of lambda
p2p3_lassom <- glmnet::glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, nlambda=100)
print(p2p3_lassom)
p2p3_cv_lassom <- cv.glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, nfolds=10, type.measure="mse")
plot(p2p3_cv_lassom)
print(p2p3_cv_lassom)
p2p3_optimal_lassom <- glmnet::glmnet(x=p2p3_pred, y=p2p3_out, family="gaussian", alpha=1, lambda=0.03343)
#plot
cf1 <- c()
cf2 <- c()
for (i in 1:37) {
cf1 <- append(cf1, rownames(p2p3_optimal_lassom$beta)[i])
cf2 <- append(cf2, unname(p2p3_optimal_lassom$beta)[i])
}
cf <- data.frame(cf1, cf2)
ggplot(data=cf, aes(x=cf1, y=cf2)) +
geom_bar(stat="identity", width=0.75) + coord_flip() +
labs(x="Features", y="Coefficient Estimate") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5),
axis.title.x = element_text(face="bold", colour="red", size = 12),
axis.title.y = element_text(face="bold", colour="red", size = 12))
data.frame(
epe_full_lm = lm_pred_metrics(p2p1_m),
epe_subset_lm = lm_pred_metrics(p2p1_imp_pred_m),
epe_optimal_ridge = min(p2p2_cv_ridgem$cvm),
epe_optimal_lasso = min(p2p3_cv_lassom$cvm))
#delete variable episode_name
o_test <- o_test %>% select(-episode_name)
#split variable season into 9 variables
dummy_o_test <- caret::dummyVars("~.", data=o_test)
o_test <- data.frame(predict(dummy_o_test, newdata=o_test))
p2p4_pred_mat <- as.matrix(o_test[,-38])
p2p4_pred_df_full <- o_test[,-38]
p2p4_pred_df_imp <- o_test %>% select(season.Season.3, season.Season.1, paul_lieberstein, mindy_kaling, justin_spitzer, greg_daniels, b_j_novak, imdb_rating)
#predictions
o_test$full_lm <- predict(p2p1_m, newdata=p2p4_pred_df_full)
o_test$subset_lm <- predict(p2p1_imp_pred_m, newdata=p2p4_pred_df_imp)
o_test$optimal_ridge <- predict(p2p2_optimal_ridgem, newx=p2p4_pred_mat)
o_test$optimal_lasso <- predict(p2p3_optimal_lassom, newx=p2p4_pred_mat)
#mse comparison
data.frame(
mse_full_lm = mse(o_test$imdb_rating, o_test$full_lm),
mse_subset_lm = mse(o_test$imdb_rating, o_test$subset_lm),
mse_optimal_ridge = mse(o_test$imdb_rating, o_test$optimal_ridge),
mse_optimal_lasso = mse(o_test$imdb_rating, o_test$optimal_lasso))
#initial recoding: use c_train_q4 moving on for consistence
c_train_q4 <- c_train
c_train_q4$Outstate <- log(c_train$Outstate)
approachPlot <- qplot(x=S.F.Ratio, y=Outstate, data=c_train_q4, geom=c("point","smooth"), ylab="out of state tuition", xlab="student/faculty ratio")
approachPlot
# It looks quite linear, but could also be a second/third degree polynomial relationship. Compare the first smooth graph with the second one plotting in linear model, we can see that the relationship has a linear trend since the two plots look quite similar.
lmApprochPlot <- qplot(x=S.F.Ratio, y=Outstate, data=c_train_q4, geom=c("point","smooth"), method="lm", ylab="out of state tuition", xlab="student/faculty ratio")
lmApprochPlot
# we reuse the function from problem set 2 for the wealth of non-simulation based estimates of the expected prediction error to make this decision
lm_pred_metrics <- function(fit_model) {
#log-likelihood
N <- length(fit_model$residuals)
sig <- sigma(fit_model)
res <- fit_model$residuals
ll <- -N/2*log10(2*pi) - N/2*log10(sig^2) - 1/(2*sig^2)*sum(res^2)
#AIC
d <- length(fit_model$coefficients) + 1
AIC <- -2*ll + 2*(d)
#BIC
BIC <- -2*ll + d*log10(N)
#LOOCV
LOOCV <- (res[1] / (1-hatvalues(fit_model)[1]))^2
if (N>=2){
for (i in 2:N){
LOOCV <- LOOCV + (res[i] / (1-hatvalues(fit_model)[i]))^2
}
}
LOOCV_final <- LOOCV / N
return(c("AIC"=AIC, "BIC"=BIC, "LOOCV"=LOOCV_final))
}
p4p1_model_1 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,1))
p4p1_model_2 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,2))
p4p1_model_3 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,3))
p4p1_model_4 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,4))
p4p1_model_5 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,5))
p4p1_model_6 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,6))
p4p1_model_7 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,7))
p4p1_model_8 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,8))
p4p1_model_9 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,9))
p4p1_model_10 <- lm(c_train_q4$Outstate~poly(c_train_q4$S.F.Ratio,10))
p4p1_df <- t(cbind(lm_pred_metrics(p4p1_model_1), lm_pred_metrics(p4p1_model_2), lm_pred_metrics(p4p1_model_3), lm_pred_metrics(p4p1_model_4), lm_pred_metrics(p4p1_model_5), lm_pred_metrics(p4p1_model_6), lm_pred_metrics(p4p1_model_7), lm_pred_metrics(p4p1_model_8), lm_pred_metrics(p4p1_model_9), lm_pred_metrics(p4p1_model_10)))
num <- c(1:10)
p4p1_df <- data.frame(num, p4p1_df)
#plot LOOCV for various degree of polynomial
ggplot(data=p4p1_df) +
geom_point(aes(x=num, y=LOOCV.1)) +
geom_line(aes(x=num, y=LOOCV.1)) +
xlab("degree polynomial") + ylab('LOOCV') +
theme_bw()
# We use LOOCV as our measure of EPE and find that third order of global polynomial that minimizes EPE. We choose LOOCV as there is less worry about bias and variance than other approaches and it's asymptotically unbiased for the EPE.From the graph above, we could see that the LOOCV reaches minimum for degree polynomial=3.
#optimal polynomial model
#train the model with third degree of polynomial
optimalPolyModel <- lm(c_train_q4$Outstate ~ poly(c_train_q4$S.F.Ratio,3))
polyPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,
predOutState=optimalPolyModel$fitted.values,
originalOutState=c_train_q4$Outstate)
#plot our polynomial model
polyPredResultPlot <- ggplot(data=polyPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
polyPredResultPlot
#natural spline(cubic)
#find the optimal df with our measure of EPE
p4_1_num <- seq(1,20,1)
p4_1_aic <- c()
p4_1_bic <- c()
p4_1_loocv <- c()
for (i in 1:20) {
cubicSpline <- lm(Outstate ~ ns(S.F.Ratio,df=i), data=c_train_q4)
tempCheck <- unname(lm_pred_metrics(cubicSpline))
p4_1_aic <- append(p4_1_aic, tempCheck[1])
p4_1_bic <- append(p4_1_bic, tempCheck[2])
p4_1_loocv <- append(p4_1_loocv, tempCheck[3])
}
p4_1_dat <- data.frame(p4_1_num, p4_1_aic, p4_1_bic, p4_1_loocv)
#plot how each df perform with each measure of EPE
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_aic)) +
geom_line(aes(x=p4_1_num, y=p4_1_aic)) +
xlab('df') + ylab('aic') +
theme_bw()
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_bic)) +
geom_line(aes(x=p4_1_num, y=p4_1_bic)) +
xlab('df') + ylab('bic') +
theme_bw()
ggplot(data=p4_1_dat) +
geom_point(aes(x=p4_1_num, y=p4_1_loocv)) +
geom_line(aes(x=p4_1_num, y=p4_1_loocv)) +
xlab('df') + ylab('loocv') +
theme_bw()
#optimal Natural Spline model
optimalCubicModel <- lm(Outstate ~ ns(S.F.Ratio,df=4), data=c_train_q4)
nsPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,
predOutState=optimalCubicModel$fitted.values,
originalOutState=c_train_q4$Outstate)
predResultPlot <- ggplot(data=nsPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
predResultPlot
#optimal smoothing spline model
optimalSSModel <- smooth.spline(x=c_train_q4$S.F.Ratio, y=c_train_q4$Outstate)
ssPredResult <- data.frame(S.F.Ratio=c_train_q4$S.F.Ratio,
predOutState=predict(optimalSSModel,x=c_train_q4$S.F.Ratio),
originalOutState=c_train_q4$Outstate)
predResultPlot <- ggplot(data=ssPredResult) +
geom_point(aes(x=S.F.Ratio, y=predOutState.y, col='prediction')) +
geom_point(aes(x=S.F.Ratio, y=originalOutState, col='original')) +
scale_colour_manual(name="Legend", values=c('black','red')) +
ylab('OutState') + theme_bw()
predResultPlot
#Comparing the optimal model we got through cubic natural spline and smoothing spline, we can see that optimal smoothing spline model goes more smoothly than the natural spline one, especially on the left end where S.F.ratio smaller than 15.
predict(optimalPolyModel,newdata=c_test_q4$S.F.Ratio)
c_test_q4 <- c_test
c_test_q4$Outstate <- log(c_test$Outstate)
predict(optimalPolyModel,newdata=c_test_q4$S.F.Ratio)
optimalPolyModel
predict(optimalPolyModel, newdata = c_test_q4$S.F.Ratio)
predict(optimalPolyModel, data = c_test_q4$S.F.Ratio)
predict(optimalPolyModel, newdata = c_test_q4)
predict(optimalPolyModel, newdata = c_test_q4)
#optimal polynomial model
#train the model with third degree of polynomial
optimalPolyModel <- lm(c_train_q4$Outstate ~ poly(c_train_q4$S.F.Ratio,3), data = c_train_q4)
predict(optimalPolyModel, newdata=c_test_q4)
predict(optimalPolyModel, newdata=c_test_q4)
predict(optimalPolyModel, newdata=c_test_q4$S.F.Ratio)
predict(optimalPolyModel, newdata=c_test_q4)
predict(optimalPolyModel, data=c_test_q4)
predict(optimalPolyModel, newdata=c_test_q4)
View(c_train_q4)
mse(predict(optimalPolyModel, newdata=c_test_q4),c_test_q4$Outstate)
mse(predict(optimalPolyModel, x=c_test_q4$S.F.Ratio),c_test_q4$Outstate)
#optimal polynomial model
#train the model with third degree of polynomial
optimalPolyModel <- lm(c_train_q4$Outstate ~ poly(S.F.Ratio,3), data = c_train_q4)
predict(optimalPolyModel, newdata=c_test_q4)
#train three optimal models and calculate mse
test_poly_MSE = mse(predict(optimalPolyModel, newdata=c_test_q4),c_test_q4$Outstate)
mse(predict(optimalPolyModel, newdata=c_test_q4),c_test_q4$Outstate)
